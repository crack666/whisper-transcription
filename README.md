# ğŸ“ Whisper Transcription Tool v2.2

**Professionelles Transkriptions-Tool** fÃ¼r Vorlesungen, Meetings und Interviews mit KI-Spracherkennung (OpenAI Whisper), automatischer Screenshot-Extraktion und interaktiven HTML-Reports.

## ğŸš€ Schnellstart

```bash
# Einzelnes Video transkribieren - fertig!
python study_processor_v2.py --input video.mp4

# Ergebnis: Alles im selben Verzeichnis
# â†’ video_report.html (interaktive Timeline)
# â†’ video_transcript.txt (reiner Text)
# â†’ video_analysis.json (strukturierte Daten)
# â†’ video_screenshots/ (automatische Screenshots)
```

**Das war's!** ğŸ‰ Alle Ergebnisse landen automatisch neben Ihrer Quelldatei.

## âš¡ Was macht dieses Tool?

**Sie geben:** `video.mp4` oder `audio.mp3`

**Sie bekommen automatisch:**
- ğŸ“ **VollstÃ¤ndiges Transkript** mit Zeitstempeln
- ğŸ–¼ï¸ **Intelligente Screenshots** bei Folienwechseln
- ğŸŒ **Interaktiver HTML-Report** mit Timeline und Suche
- ğŸ“„ **Plain-Text-Export** fÃ¼r Copy-Paste
- ğŸ“Š **JSON-Daten** fÃ¼r programmatische Nutzung

### Hauptmerkmale

- âœ… **Plug & Play** - Einfach starten, keine Konfiguration
- âš¡ **Schnell** - 1h Video in ~19min mit optimaler QualitÃ¤t
- ğŸ¯ **PrÃ¤zise** - OpenAI Whisper `large-v3` mit Segmentation (eliminiert Halluzinationen)
- ğŸ“‚ **Organisiert** - Alle Dateien sauber strukturiert
- ğŸ”„ **Batch-fÃ¤hig** - Ganze Ordner auf einmal

> **ğŸ’¡ Wichtig:** Der Standard-Modus nutzt **Segmentation** fÃ¼r beste QualitÃ¤t und verhindert typische Whisper-Halluzinationen (repetitive WÃ¶rter, Zahlenreihen). Dies ist der empfohlene Modus!

## ï¿½ Einfache Anwendungsbeispiele

### Basis-Nutzung (ein Kommando!)

```bash
# Einzelnes Video transkribieren
python study_processor_v2.py --input lecture.mp4

# Einzelne Audio-Datei
python study_processor_v2.py --input interview.mp3

# Ganzen Ordner verarbeiten
python study_processor_v2.py --input ./videos/ --batch
```

### HÃ¤ufige Use Cases

```bash
# ğŸ“‚ Mit eigenem Output-Ordner
python study_processor_v2.py --input video.mp4 --output ./ergebnisse

# ğŸ¯ Nur Audio, keine Screenshots
python study_processor_v2.py --input audio.mp3 --no-screenshots

# âš¡ Speed-Optimierung (schneller, aber ohne Segmentation)
python study_processor_v2.py --input video.mp4 --model large-v3-turbo

# ğŸ“š Batch-Verarbeitung mit QualitÃ¤ts-Modus
python study_processor_v2.py --input ./vorlesungen/ --batch --output ./results
```

### Was Sie bekommen

```
ğŸ“ Ihr Video-Verzeichnis/
â”œâ”€â”€ video.mp4                        # Ihr Original
â”œâ”€â”€ video_transcript.txt             # âœ¨ Reiner Text mit Zeitstempeln
â”œâ”€â”€ video_report.html                # âœ¨ Interaktive Timeline + Suche
â”œâ”€â”€ video_analysis.json              # âœ¨ Alle Daten strukturiert
â””â”€â”€ ğŸ“ video_screenshots/            # âœ¨ Automatische Screenshots
    â”œâ”€â”€ screenshot_000_00-00-05.jpg
    â”œâ”€â”€ screenshot_001_00-02-34.jpg
    â””â”€â”€ ...
```

**Komplett automatisch. Keine Konfiguration nÃ¶tig.** ğŸ‰

---

## âš¡ Performance & QualitÃ¤t

### ğŸ¯ Empfohlener Modus: **Segmentation** (Standard)

```bash
# â­ Standard & Empfohlen - Beste QualitÃ¤t
python study_processor_v2.py --input video.mp4
# â†’ ~19 min fÃ¼r 1h Video mit large-v3 + Segmentation
# âœ… Keine Halluzinations-Artefakte (repetitive WÃ¶rter, Zahlenreihen)
# âœ… Bessere Umgang mit Pausen und Sprecherwechseln
```

**Warum Segmentation?**
- âœ… **Deutlich bessere QualitÃ¤t:** Eliminiert typische Whisper-Halluzinationen (z.B. 20x "ja ja ja..." oder "1, 2, 3... 100")
- âœ… **Robuster bei Pausen:** Bessere Handhabung von lÃ¤ngeren Stillephasen
- âœ… **Nur ~3min langsamer:** Minimaler Performance-Overhead fÃ¼r deutlich bessere Ergebnisse

### Alternative: Whole-File Modus

```bash
# ğŸš€ Ohne Segmentation (schneller, aber anfÃ¤lliger fÃ¼r Artefakte)
python study_processor_v2.py --input video.mp4 --no-segmentation
# â†’ ~22 min fÃ¼r 1h Video mit large-v3 (ohne Segmentation)
# âš ï¸ Kann Halluzinations-Artefakte erzeugen bei langen Videos
```

**Nutze --no-segmentation nur wenn:**
- Sehr kurze Videos (<10 Min)
- Kontinuierlicher Sprachfluss ohne groÃŸe Pausen
- Speed ist wichtiger als maximale QualitÃ¤t

### Modell-Auswahl

```bash
# ğŸ† Beste QualitÃ¤t (Standard) - EMPFOHLEN
python study_processor_v2.py --input video.mp4 --model large-v3

# âš¡ Schneller mit guter QualitÃ¤t
python study_processor_v2.py --input video.mp4 --model large-v3-turbo
```

| Modell | QualitÃ¤t | Zeit (1h Video) | Speedup | Empfohlen fÃ¼r |
|--------|----------|-----------------|---------|---------------|
| `large-v3` + Segmentation | â­â­â­â­â­ | ~19 min | 3.25x | **Standard & Beste QualitÃ¤t** âœ… |
| `large-v3` ohne Segmentation | â­â­â­â­ | ~22 min | 2.87x | Kurze Videos |
| `large-v3-turbo` | â­â­â­â­â­ | ~13 min | 5.64x | Speed-optimiert |

**Benchmark-Referenz:**
- Hardware: NVIDIA RTX 5090, AMD Ryzen 7950X
- Test-Video: 1h Vorlesung (3746 Sekunden)
- Alle Zeiten mit Screenshot-Extraktion

**ğŸ’¡ Empfehlung:** `large-v3` mit Segmentation (Standard) fÃ¼r beste TranskriptionsqualitÃ¤t ohne Halluzinationen!

---

## ï¿½ï¸ Installation

```bash
# 1. Repository klonen
git clone <repository-url>
cd whisper-transcription

# 2. Dependencies installieren
pip install -r requirements.txt

# 3. FFmpeg installieren (falls noch nicht vorhanden)
# Windows: https://ffmpeg.org/download.html
# Ubuntu: sudo apt install ffmpeg
# macOS: brew install ffmpeg

# 4. Test
python study_processor_v2.py --validate
```

**Fertig!** Sie kÃ¶nnen jetzt Videos transkribieren. ğŸš€

## ğŸ¯ Erweiterte AnwendungsfÃ¤lle

### Spezielle Szenarien

```bash
# ğŸ“„ Mit PDF-VerknÃ¼pfung (findet relevante Dokumente)
python study_processor_v2.py --input lecture.mp4 --studies ./pdf_materials

# ğŸŒ Andere Sprache
python study_processor_v2.py --input video.mp4 --language english

# ï¿½ï¸ GPU-Beschleunigung nutzen
python study_processor_v2.py --input video.mp4 --device cuda

# ğŸ§¹ TemporÃ¤re Dateien aufrÃ¤umen
python study_processor_v2.py --input video.mp4 --cleanup-audio

# ğŸ¨ Screenshot-SensitivitÃ¤t anpassen
python study_processor_v2.py --input video.mp4 --similarity-threshold 0.90
```

### Utility-Tools (optional)

```bash
# ğŸ”„ Screenshots nachtrÃ¤glich regenerieren
python regenerate_screenshots.py "video_analysis.json"

# ğŸ“„ HTML-Report neu erstellen
python regenerate_report.py

# ğŸ“ Text separat extrahieren (bereits automatisch, aber fÃ¼r Legacy-Workflows)
python extract_transcript_text.py --input video_analysis.json --timestamps
```

---

## ğŸ“Š Output-Beispiele

### ğŸ“ Text-Transkript (`video_transcript.txt`)
```
================================================================================
TRANSCRIPTION
================================================================================

Language: de
Duration: 104.8 minutes (6288.0 seconds)
Segments: 267
Words: 12453

================================================================================

[00:00:00] Guten Morgen zusammen, herzlich willkommen zur heutigen Vorlesung...
[00:05:23] Wie Sie auf der Folie sehen kÃ¶nnen, haben wir drei Hauptpunkte...
[00:12:45] Das ist ein sehr wichtiger Aspekt, den wir uns genauer ansehen...
```

### ğŸŒ HTML-Report Features

Der interaktive HTML-Report bietet:
- **ğŸ“ Timeline-Navigation** - Durch alle Segmente scrollen
- **ğŸ” Volltext-Suche** - Schnell bestimmte Stellen finden
- **ğŸ–¼ï¸ Screenshot-Sync** - Automatische Anzeige passender Screenshots
- **ğŸ“Š Statistiken** - Dauer, WÃ¶rter, Confidence-Werte
- **ğŸ“± Responsive** - Funktioniert auf allen GerÃ¤ten

### ğŸ“‚ Ordnerstruktur

**Standard (ohne --output):**
```
ğŸ“ videos/
â”œâ”€â”€ lecture.mp4                    # Original
â”œâ”€â”€ lecture_transcript.txt         # Text mit Zeitstempeln
â”œâ”€â”€ lecture_report.html            # Interaktiver Report
â”œâ”€â”€ lecture_analysis.json          # Strukturierte Daten
â””â”€â”€ ğŸ“ lecture_screenshots/        # Screenshots getrennt
    â”œâ”€â”€ screenshot_000.jpg
    â””â”€â”€ ...
```

**Mit --output:**
```
ğŸ“ results/
â””â”€â”€ ğŸ“ lecture/
    â”œâ”€â”€ lecture_transcript.txt
    â”œâ”€â”€ lecture_report.html
    â”œâ”€â”€ lecture_analysis.json
    â””â”€â”€ ğŸ“ screenshots/
        â””â”€â”€ ...
```

---

## âš™ï¸ Alle Parameter (Referenz)

### HÃ¤ufig verwendet
```bash
--input FILE/DIR           # Video/Audio-Datei oder Ordner (ERFORDERLICH)
--output DIR               # Ausgabe-Verzeichnis (Standard: wie Input)
--batch                    # Alle Dateien im Input-Ordner verarbeiten
--no-segmentation          # Performance-Modus (3-7x schneller)
--model NAME               # large-v3 (Standard), medium, base
--language LANG            # german (Standard), english, etc.
```

### Weitere Optionen
```bash
--device TYPE              # cuda, cpu (Standard: auto)
--no-screenshots           # Screenshots deaktivieren
--no-html                  # HTML-Report deaktivieren
--similarity-threshold N   # Screenshot-SensitivitÃ¤t (0.0-1.0, Standard: 0.85)
--min-interval N           # Min. Sekunden zwischen Screenshots (Standard: 2.0)
--cleanup-audio            # TemporÃ¤re Audio-Dateien lÃ¶schen
--studies DIR              # PDF-Verzeichnis fÃ¼r Dokumenten-Matching
--config FILE              # Eigene Konfigurationsdatei
--verbose                  # Detaillierte Logs
--debug                    # Debug-Modus
--validate                 # System-Check ohne Verarbeitung
```

---

## ï¿½ Tipps & Tricks

### Optimale Einstellungen finden

```bash
# FÃ¼r neuen Sprecher/Content automatisch optimieren
python auto_optimize.py --input sample.mp4 --quick

# Dann fÃ¼r alle weiteren Videos nutzen
python study_processor_v2.py --input weitere/ --batch \
  --config configs/auto_optimized_*.json
```

### Performance vs. QualitÃ¤t

| Szenario | Kommando | Zeit (1h Video) | QualitÃ¤t |
|----------|----------|-----------------|----------|
| ğŸ† **Beste QualitÃ¤t (Standard)** | `--model large-v3` | ~19 min | â­â­â­â­â­ |
| âš¡ **Speed-optimiert** | `--model large-v3-turbo` | ~13 min | â­â­â­â­â­ |
| ï¿½ **Schnellster (Kompromiss)** | `--model large-v3 --no-segmentation` | ~22 min | â­â­â­â­ |

**Basierend auf echten Benchmarks** (RTX 5090, 1h Vorlesungsvideo)

### Batch-Verarbeitung groÃŸe Mengen

```bash
## ğŸ’¡ Tipps & Tricks

### Batch-Verarbeitung

```bash
# Empfohlener Workflow fÃ¼r viele Videos
python study_processor_v2.py \
  --input ./semester_videos/ \
  --batch \
  --no-segmentation \
  --cleanup-audio \
  --device cuda
```

### ğŸ“Š Performance Benchmarking

Das Tool sammelt **automatisch Performance-Daten** fÃ¼r alle Runs:

```bash
# Statistiken anzeigen
python view_benchmarks.py

# Nach Modell filtern
python view_benchmarks.py --model large-v3

# Letzte 5 Runs
python view_benchmarks.py --last 5

# Als JSON exportieren
python view_benchmarks.py --export stats.json
```

**Nutzen:**
- ğŸ¯ Finde das **optimale Modell fÃ¼r deine Hardware**
- ğŸ“ˆ Vergleiche **echte Performance-Daten** statt SchÃ¤tzungen
- ğŸ’» Erstelle **hardware-spezifische Empfehlungen**
- ğŸ“Š Erkenne **Performance-Regressionen** nach Updates

Siehe [BENCHMARKING_GUIDE.md](BENCHMARKING_GUIDE.md) fÃ¼r Details.

### Performance vs. QualitÃ¤t

**âš ï¸ Hinweis:** Die folgenden Zeiten sind Richtwerte. Nutze `view_benchmarks.py` fÃ¼r **deine echten Hardware-Daten**.

| Szenario | Kommando | Zeit (1h Video) |
|----------|----------|-----------------|
| Maximum KompatibilitÃ¤t | Standard | ~15-20 min |
| Balanced | `--model medium` | ~10-15 min |
| Maximum Speed | `--model medium --no-segmentation` | ~3-5 min |
| Maximum QualitÃ¤t | `--model large-v3` | ~15-25 min |
| Optimal | `--model large-v3 --no-segmentation` | ~5-10 min |
```

---

## ğŸ“š HÃ¤ufige Fragen (FAQ)

### Welches Modell soll ich verwenden?
- **Empfohlen:** `large-v3` (Standard) - beste QualitÃ¤t
- **Schneller:** `medium` - guter Kompromiss
- **Tests:** `base` - am schnellsten

### Brauche ich eine GPU?
- **Nein** - funktioniert auch mit CPU (langsamer)
- **Ja, hilft** - mit CUDA-GPU 2-3x schneller
- **Auto-Erkennung** - Tool wÃ¤hlt automatisch beste Option

### Wo landen meine Dateien?
- **Ohne --output:** Direkt neben der Quelldatei âœ… (empfohlen)
- **Mit --output:** In angegebenem Verzeichnis

### Wie groÃŸ sollte mein RAM sein?
- **Standard-Modus:** 8GB ausreichend
- **Performance-Modus:** 16GB empfohlen
- **Lange Videos (>2h):** 16-32GB

### UnterstÃ¼tzte Formate?
- **Video:** MP4, AVI, MKV, MOV, WEBM, FLV, WMV
- **Audio:** MP3, WAV, M4A, FLAC, OGG

### Wie lange dauert die Verarbeitung?
- **Standard:** ~15-20 min fÃ¼r 1h Video (geschÃ¤tzt)
- **Performance-Modus:** ~5-10 min fÃ¼r 1h Video (geschÃ¤tzt)
- **ğŸ“Š FÃ¼r echte Werte:** `python view_benchmarks.py` nach einigen Runs

### Was ist Benchmarking?
- **Automatisch:** Jeder Run wird geloggt (Zeit, Hardware, Modell)
- **Analyse:** `python view_benchmarks.py` zeigt Performance-Stats
- **Nutzen:** Finde optimale Einstellungen fÃ¼r **deine** Hardware
- **Details:** Siehe [BENCHMARKING_GUIDE.md](BENCHMARKING_GUIDE.md)
- **AbhÃ¤ngig von:** Hardware, Modell, Segmentierung

---