# ğŸ“ Study Material Processor v2.0

**Intelligentes System** zur automatischen Verarbeitung von Vorlesungsvideos und Audio-Dateien mit KI-basierter Transkription, Auto-Optimierung und Screenshot-Extraktion.

## âš¡ Wichtigste Features

- ğŸ§  **Auto-Optimierung** - Findet automatisch die besten Einstellungen fÃ¼r jeden Sprecher
- ğŸ¯ **Hohe Erkennungsrate** - Bis zu 172+ WÃ¶rter pro Minute fÃ¼r deutsche Vorlesungen
- ğŸ“Š **Intelligente Anpassung** - Erkennt Sprechstile automatisch (langsam/schnell/Pausen)
- ğŸ“¹ **VollstÃ¤ndige Verarbeitung** - Audio + Video + Screenshots + HTML-Reports
- ğŸ”„ **Batch-Verarbeitung** - Automatische Verarbeitung ganzer Ordner

---

## ğŸš€ Einfacher Start (3 Schritte)

### 1. ğŸ¯ FÃ¼r neue Sprecher/Module (EMPFOHLEN)
```bash
# Automatische Optimierung - findet beste Einstellungen
python auto_optimize.py --input your_lecture.mp4
```

### 2. ğŸ“š Standard-Verarbeitung  
```bash
# VollstÃ¤ndige Verarbeitung mit optimalen Einstellungen
python study_processor_v2.py --input your_lecture.mp4 --output ./results
```

### 3. ğŸ”„ Weitere Videos mit gleichen Einstellungen
```bash
# Nutze die auto-generierte Konfiguration fÃ¼r weitere Videos
python study_processor_v2.py --input weitere_videos/ --batch --config configs/auto_optimized_*.json
```

**Das war's! ğŸ‰** Das System erstellt automatisch optimierte Transkriptionen, Screenshots und HTML-Reports.

---

## ğŸ› ï¸ Installation

```bash
# 1. Python-AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# 2. FFmpeg installieren (falls nicht vorhanden)
# Windows: Download von https://ffmpeg.org/
# Ubuntu: sudo apt install ffmpeg  
# macOS: brew install ffmpeg

# 3. Setup testen
python study_processor_v2.py --validate
```

---

## ğŸ“š HauptanwendungsfÃ¤lle

### ğŸ™ï¸ Nur Audio transkribieren
```bash
# Einzelne Audio-Datei (MP3, WAV, etc.)
python study_processor_v2.py --input lecture.mp3 --no-screenshots

# Alle Audio-Dateien in einem Ordner
python study_processor_v2.py --input ./audio_files --batch --no-screenshots
```

### ğŸ“¹ Videos mit Screenshots
```bash
# Einzelnes Video (Standard - empfohlen)
python study_processor_v2.py --input lecture.mp4 --output ./results

# Batch: Alle Videos in einem Ordner
python study_processor_v2.py --input ./videos --batch --output ./results
```

### ğŸ“„ VollstÃ¤ndige Analyse mit PDFs
```bash
# Video + Screenshots + PDF-VerknÃ¼pfung + HTML-Report
python study_processor_v2.py \
  --input lecture.mp4 \
  --output ./results \
  --studies ./pdf_materials
```

---

## âš™ï¸ Wichtige Parameter

### QualitÃ¤t optimieren
```bash
--config configs/lecture_optimized_v2.json    # Beste Erkennungsrate (172+ WÃ¶rter)
--model large-v3                              # Bestes Whisper-Modell
--language german                             # Sprache festlegen
```

### Performance anpassen  
```bash
--device cuda                                 # GPU verwenden (schneller)
--cleanup-audio                               # TemporÃ¤re Dateien lÃ¶schen
--batch                                       # Alle Dateien im Ordner
```

### Features ein/ausschalten
```bash
--no-screenshots                              # Screenshots deaktivieren
--no-html                                     # HTML-Report deaktivieren
--similarity-threshold 0.85                   # Screenshot-SensitivitÃ¤t
```

---

## ğŸ“Š Was wird erstellt?

### Ordnerstruktur
```
results/
â”œâ”€â”€ LectureName/
â”‚   â”œâ”€â”€ LectureName_analysis.json           # ğŸ“Š Strukturierte Daten + Timestamps
â”‚   â”œâ”€â”€ LectureName_report.html            # ğŸŒ Interaktiver HTML-Report  
â”‚   â”œâ”€â”€ LectureName_transcript.txt         # ğŸ“ Einfacher Text
â”‚   â””â”€â”€ screenshots/                       # ğŸ“¸ Screenshots mit Zeitstempel
â”‚       â”œâ”€â”€ LectureName_screenshot_000_00-05-23.jpg
â”‚       â””â”€â”€ LectureName_screenshot_001_00-12-45.jpg
â””â”€â”€ index.html                             # ğŸ“‘ Ãœbersichtsseite (bei --batch)
```

### ğŸŒ HTML-Report Features
- ğŸ” **Volltext-Suche** Ã¼ber Transkript und Screenshots
- ğŸ“‘ **Navigation** zwischen verschiedenen Zeitstellen
- ğŸ–¼ï¸ **Screenshot-Timeline** mit prÃ¤ziser Zuordnung  
- ğŸ“Š **QualitÃ¤tsmetriken** und Statistiken
- ğŸ“± **Mobile-optimiert** fÃ¼r alle GerÃ¤te

---

## ğŸš€ Performance-Tipps

### Modell-Auswahl
| Anwendung | Empfehlung | Grund |
|-----------|------------|-------|
| **Neue Sprecher** | `auto_optimize.py` | ğŸ§  Automatische Optimierung |
| **Beste QualitÃ¤t** | `--config lecture_optimized_v2.json` | ğŸ† 172+ WÃ¶rter/Minute |
| **Schnelle Tests** | `--model medium` | âš¡ Guter Kompromiss |
| **Batch-Verarbeitung** | `--config lecture_balanced.json` | âš–ï¸ QualitÃ¤t + Geschwindigkeit |

### Effiziente Workflows
```bash
# 1. Optimierung fÃ¼r neuen Professor
python auto_optimize.py --input sample_lecture.mp4 --quick

# 2. Alle weiteren Videos mit optimaler Config  
python study_processor_v2.py --input ./all_lectures --batch --config configs/auto_optimized_*.json

# 3. GroÃŸe Mengen (RAM sparen)
python study_processor_v2.py --input ./videos --batch --cleanup-audio --device cpu
```

---

## ğŸ¯ Audio-Segmentierung & Splitting-Modi

Das System bietet verschiedene intelligente Segmentierungsmodi fÃ¼r optimale TranskriptionsqualitÃ¤t:

### ğŸ›¡ï¸ Defensive Silence Detection (EMPFOHLEN fÃ¼r Performance)
**Der neue "smarte" Performance-Modus** - splittet nur bei sicheren Stille-Phasen.

```bash
# Explizit aktivieren fÃ¼r maximale Geschwindigkeit
python study_processor_v2.py --input lecture.mp4 --config defensive_silence
```

**âœ¨ Neue Testergebnisse (Mai 2025):**
- ğŸš€ **7x schneller** als adaptive Segmentierung (21.2 vs 3.0 WÃ¶rter/Sekunde)
- ğŸ¯ **Identische QualitÃ¤t** bei deutschen Vorlesungen
- âš¡ **Echte Alternative** zu adaptive Segmentierung
- ğŸ† **Best Performance/Quality Ratio**

**Funktionsweise:**
- ğŸ“Š **Statistische Analyse** der Audio-LautstÃ¤rke
- ğŸ” **Schwellwert-Berechnung**: Mittelwert - 1.5 Ã— Standardabweichung  
- â±ï¸ **Mindest-Stille**: 2000ms fÃ¼r sicheres Splitting
- ğŸ¯ **Konservativ**: Weniger, aber lÃ¤ngere Segmente
- âš¡ **Performance**: 7x schneller als adaptive Modi

**Vorteile:**
- âœ… Keine Wort-AbbrÃ¼che mitten im Satz
- âœ… NatÃ¼rliche Segmentgrenzen bei Sprechpausen
- âœ… **7x schnellere Verarbeitung** als Adaptive
- âœ… Identische TranskriptionsqualitÃ¤t bei deutschen Vorlesungen

### â° Fixed-Time Segmentierung
**Zeitbasierte Aufteilung** fÃ¼r gleichmÃ¤ÃŸige Segmente.

```bash
# Aktivierung Ã¼ber Konfiguration
{
  "segmentation_mode": "fixed_time",
  "fixed_time_duration": 30000,    // 30 Sekunden pro Segment
  "fixed_time_overlap": 2000       // 2 Sekunden Ãœberlappung
}
```

**Funktionsweise:**
- â±ï¸ **Feste Dauer**: Standard 30 Sekunden pro Segment
- ğŸ”„ **Ãœberlappung**: 2 Sekunden zur KontinuitÃ¤tssicherung
- ğŸ“ **Vorhersagbar**: GleichmÃ¤ÃŸige SegmentlÃ¤ngen
- ğŸ¯ **Robust**: Funktioniert bei allen Audio-Typen

### ğŸ”Š Erweiterte Silence Detection
**Klassische Stille-Erkennung** mit Feinjustierung.

```bash
# Manuelle Konfiguration
{
  "segmentation_mode": "silence_detection",
  "min_silence_len": 2000,         // Mindest-Stille in ms
  "silence_adjustment": 5.0        // Schwellwert-Anpassung
}
```

### ğŸ§  Adaptive Segmentierung (EMPFOHLEN fÃ¼r QualitÃ¤t)
**KI-basierte Anpassung** an Audio-Eigenschaften mit defensive silence Prinzipien.

```bash
# Automatische Erkennung optimaler Parameter (Standard)
{
  "segmentation_mode": "adaptive"
}
```

**âœ¨ Neue Verbesserungen (Mai 2025):**
- ğŸ›¡ï¸ **Integriert defensive silence Prinzipien** zur Duplikat-Vermeidung
- ğŸš« **Keine Ã¼berlappenden Segmente** mehr
- ğŸ¯ **Dreistufige Fallback-Strategie**: defensive silence â†’ enhanced detection â†’ defensive-guided fixed-time
- ğŸ† **HÃ¶chste QualitÃ¤t** bei komplexeren Audio-Charakteristiken

**Wann verwenden:**
- ğŸ“š Akademische Interviews und Forschung
- ğŸ‘¥ Verschiedene Sprecher in einem Audio
- ğŸ¯ Wenn QualitÃ¤t wichtiger als Geschwindigkeit ist

### ğŸ”¬ Precision Waveform Detection (NEUESTE INNOVATION)
**Wissenschaftliche Wellenform-Analyse** fÃ¼r hÃ¶chste PrÃ¤zision bei der Spracherkennung.

```bash
# Aktivierung Ã¼ber Konfiguration
{
  "segmentation_mode": "precision_waveform",
  "precision_waveform_config": {
    "frame_size_ms": 50,              // Analyse-Fenster (50ms fÃ¼r hÃ¶chste PrÃ¤zision)
    "hop_size_ms": 25,                // Ãœberlappung zwischen Fenstern
    "min_speech_duration_ms": 500,    // Minimale Sprach-Segmentdauer
    "min_silence_duration_ms": 1000,  // Minimale Stille-Dauer
    "volume_percentile_threshold": 20, // Schwellwert (20. Perzentil)
    "adaptive_threshold": true,        // Automatische Schwellwert-Anpassung
    "merge_close_segments": true       // Nahe Segmente zusammenfassen
  },
  "speaker_type": "moderate"           // sparse, moderate, dense
}
```

**ğŸ§¬ Wissenschaftliche Analyse-Methoden:**
- ğŸ“Š **Frame-basierte Analyse**: Mathematische Zerlegung in 50ms-Fenster
- âš¡ **Energy & RMS Berechnung**: PrÃ¤zise Energie- und Quadratmittel-Analyse
- ğŸŒŠ **Zero-Crossing-Rate**: Spektrale Inhaltsanalyse fÃ¼r Sprachdetektion
- ğŸ“ˆ **Perzentil-basierte Schwellwerte**: Robuste statistische Methoden
- ğŸ”— **Segment-Fusion**: Intelligente ZusammenfÃ¼hrung naher Sprachsegmente

**ğŸ¯ ProblemlÃ¶sung:** 
Entwickelt als Antwort auf das Problem, dass **viele Sprachsegmente Ã¼bersehen** wurden, obwohl sie in der Wellenform-Visualisierung deutlich sichtbar waren.

**âš™ï¸ Konfigurationsprofile:**

```json
// PRECISION_CONFIG - Maximale Genauigkeit
{
  "frame_size_ms": 50,
  "hop_size_ms": 25,
  "min_speech_duration_ms": 500,
  "volume_percentile_threshold": 20
}

// CONSERVATIVE_CONFIG - Stabile Erkennung  
{
  "frame_size_ms": 200,
  "hop_size_ms": 100,
  "min_speech_duration_ms": 2000,
  "volume_percentile_threshold": 30
}

// LECTURE_CONFIG - Optimiert fÃ¼r Vorlesungen
{
  "frame_size_ms": 100,
  "hop_size_ms": 50,
  "min_speech_duration_ms": 1000,
  "volume_percentile_threshold": 25
}
```

**ğŸ”¬ Wissenschaftliche Features:**
- ğŸ“Š **Waveform-Visualisierung**: Automatische Erstellung von Analyse-Diagrammen
- ğŸ“ˆ **Energie-Statistiken**: Dynamikbereich und Verteilungsanalyse  
- ğŸ¯ **Segment-Coverage**: Prozentuale Sprachabdeckung berechnen
- ğŸ” **Debug-Modus**: Detaillierte Frame-fÃ¼r-Frame Analyse

**ğŸ† Vorteile:**
- âœ… **Keine Ã¼bersehenen Sprachsegmente** mehr
- âœ… **Mathematisch prÃ¤zise** Schwellwert-Berechnung
- âœ… **Adaptiv** an verschiedene Audio-Charakteristiken
- âœ… **Wissenschaftlich validiert** durch Wellenform-Analyse
- âœ… **Visualisierung** fÃ¼r QualitÃ¤tskontrolle

**âš ï¸ Hinweise:**
- ğŸ§ª **Experimentelles Feature** (Mai 2025)
- ğŸ“¦ **ZusÃ¤tzliche AbhÃ¤ngigkeiten**: numpy, matplotlib
- â±ï¸ **Etwas langsamere Verarbeitung** durch detaillierte Analyse
- ğŸ¯ **Ideal fÃ¼r kritische Aufnahmen** wo jedes Wort wichtig ist

### ğŸ›ï¸ Konfiguration & Aktivierung

#### Via Konfigurationsdatei
```json
{
  "segmentation_mode": "defensive_silence",  // Modus wÃ¤hlen
  "min_silence_len": 2000,                   // Weitere Parameter
  "fixed_time_duration": 30000
}
```

#### Via Code (Enhanced Transcriber)
```python
from src.enhanced_transcriber import EnhancedAudioTranscriber

# Defensive Silence (empfohlen)
transcriber = EnhancedAudioTranscriber(
    model_name="small",
    language="german",
    config={"segmentation_mode": "defensive_silence"}
)

# Fixed-Time
transcriber = EnhancedAudioTranscriber(
    model_name="small", 
    language="german",
    config={
        "segmentation_mode": "fixed_time",
        "fixed_time_duration": 30000,
        "fixed_time_overlap": 2000
    }
)
```

### ğŸ“Š Performance-Vergleich (2.3min deutscher UniversitÃ¤tsvortrag)

| Modus | Segmente | WÃ¶rter | Zeit | Geschw. | QualitÃ¤t | Empfehlung |
|-------|----------|--------|------|---------|----------|------------|
| **ğŸ›¡ï¸ Defensive Silence** | 4 | 352 | **10.2s** | **21.2 w/s** | â­â­â­ | ğŸ† **Performance** |
| **ğŸ§  Improved Adaptive** | 4 | 344 | 113.2s | 3.0 w/s | â­â­â­â­ | ğŸ¯ **QualitÃ¤t** |
| â° Fixed-Time 30s | 6 | 378 | 10.1s | 37.4 w/s | â­â­ | âš–ï¸ **VollstÃ¤ndigkeit** |

**ğŸ¯ Erkenntnisse aus Tests (Mai 2025):**
- **Defensive Silence** und **Adaptive** liefern bei deutschen Vorlesungen **identische Segmentanzahl** (4 Segmente)
- **Defensive Silence** ist **7x schneller** bei praktisch gleicher QualitÃ¤t
- **Fixed-Time** erfasst mehr WÃ¶rter, erzeugt aber **Duplikate durch Ãœberlappungen**
- **Adaptive** eliminiert Ãœberlappungen vollstÃ¤ndig, ist aber langsamer

**ğŸ’¡ Neue Empfehlung:**
- ğŸš€ **Defensive Silence** fÃ¼r Produktionsumgebungen und groÃŸe Datenmengen
- ğŸ¯ **Adaptive** fÃ¼r kritische Aufnahmen wo jedes Wort zÃ¤hlt

---

## ğŸ”§ Troubleshooting

### HÃ¤ufige Probleme
```bash
# âŒ Schlechte Transkription â†’ âœ… Auto-Optimierung
python auto_optimize.py --input problematic_video.mp4

# âŒ GPU-Probleme â†’ âœ… CPU verwenden  
python study_processor_v2.py --input video.mp4 --device cpu

# âŒ Speicher-Probleme â†’ âœ… Kleineres Modell
python study_processor_v2.py --input video.mp4 --model medium --cleanup-audio

# âŒ FFmpeg fehlt â†’ âœ… Installation prÃ¼fen
ffmpeg -version
```

### Debug & Tests
```bash
# System-Check
python study_processor_v2.py --validate

# Detaillierte Logs
python study_processor_v2.py --input video.mp4 --debug --verbose
```

---

## ğŸ“– Weitere Dokumentation

- **[TRANSCRIPTION_IMPROVEMENTS.md](TRANSCRIPTION_IMPROVEMENTS.md)** - Detaillierte technische Verbesserungen
- **[CLEANUP_GUIDE.md](CLEANUP_GUIDE.md)** - Migration und Bereinigung
- **configs/** - Vordefinierte optimierte Konfigurationen

---

ğŸ‰ **Das System lernt automatisch und wird mit jedem Video besser!**